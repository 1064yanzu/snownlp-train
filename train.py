# -*- coding: utf-8 -*-
import pandas as pd
import os
import time
import sys
import shutil
from snownlp.sentiment import Sentiment
from glob import glob
from tqdm import tqdm  # è¿›åº¦æ¡åº“

# å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨å®‰è£…ï¼‰
try:
    from tqdm import tqdm
except ImportError:
    print("å®‰è£… tqdm è¿›åº¦æ¡åº“...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "tqdm"])
    from tqdm import tqdm

try:
    from snownlp.sentiment import Sentiment
except ImportError:
    print("å®‰è£… snownlp åº“...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "snownlp"])
    from snownlp.sentiment import Sentiment

# ================== æ•°æ®åŠ è½½å‡½æ•° ==================
def load_multiple_csvs(filepaths, text_col='content', label_col='sentiment'):
    """åŠ è½½å¤šä¸ªCSVæ–‡ä»¶å¹¶åˆå¹¶æ•°æ®ï¼Œè¿‡æ»¤æ‰ä¸­æ€§æ ·æœ¬ï¼Œå¸¦è¿›åº¦æ¡"""
    label_mapping = {
        'è´Ÿé¢': 0, 'æ¶ˆæ': 0, 'è´Ÿå‘': 0, 'negative': 0,
        'æ­£é¢': 1, 'ç§¯æ': 1, 'æ­£å‘': 1, 'positive': 1,
        'ä¸­æ€§': 1  # ä¸­æ€§æ ·æœ¬åˆ†é…ä¸ºæ­£é¢
    }

    all_texts, all_labels = [], []
    print(f"å¼€å§‹åŠ è½½ {len(filepaths)} ä¸ªæ•°æ®æ–‡ä»¶...")

    for path in tqdm(filepaths, desc="åŠ è½½æ–‡ä»¶"):
        if not os.path.exists(path):
            print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {path}")
            continue
            
        try:
            # å°è¯•ä¸åŒç¼–ç 
            df = None
            for encoding in ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']:
                try:
                    df = pd.read_csv(path, encoding=encoding)
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                print(f"æ— æ³•è¯»å–æ–‡ä»¶: {path}")
                continue
                
            if text_col not in df.columns or label_col not in df.columns:
                print(f"æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {path}")
                continue
                
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å¤±è´¥ {path}: {e}")
            continue
            
        texts = df[text_col].astype(str).tolist()
        labels = []
        valid_indices = []

        for i, label in enumerate(df[label_col]):
            label_str = str(label).strip().lower()
            mapped = label_mapping.get(label_str, None)

            if mapped is not None:
                labels.append(mapped)
                valid_indices.append(i)
            else:
                print(f"è­¦å‘Š: å¿½ç•¥æœªçŸ¥æ ‡ç­¾å€¼ '{label}' (æ–‡ä»¶: {path})")

        all_texts.extend([texts[i] for i in valid_indices])
        all_labels.extend(labels)

    print(f"å…±åŠ è½½ {len(all_texts)} ä¸ªæ ·æœ¬")
    pos_count = sum(1 for label in all_labels if label == 1)
    neg_count = sum(1 for label in all_labels if label == 0)
    print(f"æ­£é¢æ ·æœ¬: {pos_count}, è´Ÿé¢æ ·æœ¬: {neg_count}")
    
    return all_texts, all_labels

# ================== åˆ›å»ºæƒ…æ„Ÿè¯­æ–™æ–‡ä»¶ ==================
def create_sentiment_files(texts, labels, pos_path, neg_path):
    """åˆ›å»ºæƒ…æ„Ÿåˆ†æè¯­æ–™æ–‡ä»¶ï¼Œå¸¦è¿›åº¦æ¡"""
    os.makedirs(os.path.dirname(pos_path), exist_ok=True)

    with open(pos_path, 'w', encoding='utf-8') as f_pos, \
         open(neg_path, 'w', encoding='utf-8') as f_neg:

        print("åˆ›å»ºæƒ…æ„Ÿè¯­æ–™æ–‡ä»¶...")
        pos_count, neg_count = 0, 0

        for text, label in tqdm(zip(texts, labels), total=len(texts), desc="å¤„ç†æ ·æœ¬"):
            clean_text = text.replace('\n', '').replace('\r', '').strip()
            if len(clean_text) > 0:
                if label == 1:
                    f_pos.write(clean_text + '\n')
                    pos_count += 1
                elif label == 0:
                    f_neg.write(clean_text + '\n')
                    neg_count += 1

        print(f"åˆ›å»ºå®Œæˆ: {pos_count} ä¸ªç§¯ææ ·æœ¬, {neg_count} ä¸ªæ¶ˆææ ·æœ¬")
        return pos_count, neg_count

# ================== æ¨¡å‹è¯„ä¼°å‡½æ•° ==================
def evaluate_model(model, test_texts, test_labels):
    """è¯„ä¼°æ¨¡å‹å‡†ç¡®ç‡ï¼Œå¸¦è¿›åº¦æ¡"""
    correct = 0
    total = len(test_texts)

    for text, label in tqdm(zip(test_texts, test_labels), total=total, desc="è¯„ä¼°æ¨¡å‹"):
        try:
            score = model.classify(text)
            pred_label = 1 if score > 0.5 else 0
            if pred_label == label:
                correct += 1
        except:
            continue

    return correct / total if total > 0 else 0

# ================== åˆ›å»ºç¤ºä¾‹æ•°æ® ==================
def create_sample_data():
    """å¦‚æœæ²¡æœ‰æ•°æ®æ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®"""
    
    sample_train_data = [
        ("è¿™ä¸ªäº§å“è´¨é‡éå¸¸å¥½ï¼Œå¼ºçƒˆæ¨èï¼", "æ­£é¢"),
        ("æœåŠ¡æ€åº¦å¾ˆæ£’ï¼Œç‰©æµä¹Ÿå¾ˆå¿«", "æ­£é¢"),
        ("æ€§ä»·æ¯”å¾ˆé«˜ï¼Œå€¼å¾—è´­ä¹°", "æ­£é¢"),
        ("åŒ…è£…ç²¾ç¾ï¼Œè´¨é‡ä¸Šä¹˜", "æ­£é¢"),
        ("ä½“éªŒå¾ˆå¥½ï¼ŒåŠŸèƒ½å¼ºå¤§", "æ­£é¢"),
        ("è´¨é‡å¤ªå·®äº†ï¼Œä¸å€¼è¿™ä¸ªä»·æ ¼", "è´Ÿé¢"),
        ("æœåŠ¡æ€åº¦æ¶åŠ£ï¼Œå¾ˆä¸æ»¡æ„", "è´Ÿé¢"),
        ("ç‰©æµè¶…çº§æ…¢ï¼ŒåŒ…è£…ç²—ç³™", "è´Ÿé¢"),
        ("ç”¨äº†å‡ å¤©å°±åäº†", "è´Ÿé¢"),
        ("åŠŸèƒ½æœ‰é—®é¢˜ï¼Œæ“ä½œä¸ä¾¿", "è´Ÿé¢"),
        ("è¿˜è¡Œå§ï¼Œä¸€èˆ¬èˆ¬", "ä¸­æ€§"),
        ("ä»·æ ¼åˆç†ï¼Œè´¨é‡ä¸€èˆ¬", "ä¸­æ€§"),
        ("æ”¶åˆ°äº†ï¼Œè¿˜æ²¡ç”¨", "ä¸­æ€§"),
        ("å’Œæè¿°åŸºæœ¬ä¸€è‡´", "ä¸­æ€§"),
    ]
    
    # æ‰©å±•æ•°æ®
    extended_data = []
    for text, label in sample_train_data:
        extended_data.append((text, label))
        # æ·»åŠ ä¸€äº›å˜ä½“
        if "å¾ˆå¥½" in text:
            extended_data.append((text.replace("å¾ˆå¥½", "ä¸é”™"), label))
        if "å¤ªå·®" in text:
            extended_data.append((text.replace("å¤ªå·®", "å¾ˆå·®"), label))
    
    # ä¿å­˜è®­ç»ƒæ•°æ®
    train_df = pd.DataFrame(extended_data, columns=['content', 'sentiment'])
    train_df.to_csv('train.csv', index=False, encoding='utf-8-sig')
    print("âœ… åˆ›å»ºç¤ºä¾‹è®­ç»ƒæ•°æ®: train.csv")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    sample_test_data = [
        ("äº§å“è´¨é‡å¾ˆæ£’ï¼Œæ¨èè´­ä¹°", "æ­£é¢"),
        ("æœåŠ¡å¾ˆæ»¡æ„ï¼Œä¼šå†æ¥", "æ­£é¢"),
        ("è´¨é‡ä¸è¡Œï¼Œä¸æ¨è", "è´Ÿé¢"),
        ("å®¢æœæ€åº¦å·®ï¼Œå¾ˆå¤±æœ›", "è´Ÿé¢"),
        ("ä¸€èˆ¬èˆ¬ï¼Œå‡‘åˆç”¨", "ä¸­æ€§"),
    ]
    
    test_df = pd.DataFrame(sample_test_data, columns=['content', 'sentiment'])
    test_df.to_csv('test.csv', index=False, encoding='utf-8-sig')
    print("âœ… åˆ›å»ºç¤ºä¾‹æµ‹è¯•æ•°æ®: test.csv")

# ================== ä¸»ç¨‹åº ==================
if __name__ == "__main__":
    start_time = time.time()

    print("=" * 60)
    print("ğŸš€ SnowNLPæƒ…æ„Ÿåˆ†ææ¨¡å‹è®­ç»ƒè„šæœ¬")
    print("=" * 60)

    # ========== æ£€æŸ¥æ•°æ®æ–‡ä»¶ ==========
    train_files = []
    for pattern in ['train.csv', 'è®­ç»ƒé›†.csv', '*train*.csv']:
        train_files.extend(glob(pattern))
    
    if not train_files:
        print("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®...")
        create_sample_data()
        train_files = ['train.csv']

    test_files = []
    for pattern in ['test.csv', 'æµ‹è¯•é›†.csv', '*test*.csv']:
        test_files.extend(glob(pattern))
    
    if not test_files:
        test_files = ['test.csv']  # ä½¿ç”¨åˆ›å»ºçš„ç¤ºä¾‹æ•°æ®

    print(f"è®­ç»ƒæ–‡ä»¶: {train_files}")
    print(f"æµ‹è¯•æ–‡ä»¶: {test_files}")

    # ========== æ•°æ®å‡†å¤‡ ==========
    print("\nğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...")
    train_texts, train_labels = load_multiple_csvs(train_files)

    if not train_texts:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")
        exit(1)

    # åˆ›å»ºä¸´æ—¶æƒ…æ„Ÿè¯­æ–™æ–‡ä»¶
    pos_path = 'temp_data/pos.txt'
    neg_path = 'temp_data/neg.txt'
    pos_count, neg_count = create_sentiment_files(train_texts, train_labels, pos_path, neg_path)

    if pos_count == 0 or neg_count == 0:
        print("âŒ æ­£é¢æˆ–è´Ÿé¢æ ·æœ¬æ•°é‡ä¸º0ï¼Œæ— æ³•è®­ç»ƒ")
        exit(1)

    # åŠ è½½æµ‹è¯•é›†
    print("\nğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®...")
    test_texts, test_labels = load_multiple_csvs(test_files)

    # ========== è®­ç»ƒå‰æµ‹è¯• ==========
    if test_texts:
        print("\n" + "=" * 50)
        print("ğŸ“Š è®­ç»ƒå‰æµ‹è¯•...")
        base_model = Sentiment()
        base_acc = evaluate_model(base_model, test_texts, test_labels)
        print(f"ã€è®­ç»ƒå‰ã€‘æ¨¡å‹å‡†ç¡®ç‡ï¼š{base_acc:.2%}")

    # ========== æ¨¡å‹è®­ç»ƒ ==========
    print("\n" + "=" * 50)
    print("ğŸ”§ å¼€å§‹è®­ç»ƒæ¨¡å‹...")

    # åˆ›å»ºæ–°çš„æƒ…æ„Ÿåˆ†æå™¨å®ä¾‹
    trainer = Sentiment()

    # ç›´æ¥è®­ç»ƒæ¨¡å‹ï¼Œä¼ å…¥æ­£è´Ÿæ ·æœ¬æ–‡ä»¶è·¯å¾„
    print("æ­£åœ¨è®­ç»ƒ...")
    trainer.train(neg_path, pos_path)

    # ä¿å­˜æ¨¡å‹åˆ°å¤šä¸ªä½ç½®
    model_files = [
        'custom_sentiment.marshal.3',
        'trained_model_v1.marshal.3',
        'sentiment_model.marshal'
    ]
    
    for model_file in model_files:
        try:
            trainer.save(model_file)
            file_size = os.path.getsize(model_file)
            print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_file} ({file_size:,} å­—èŠ‚)")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥ {model_file}: {e}")

    # ========== è®­ç»ƒåæµ‹è¯• ==========
    if test_texts:
        print("\n" + "=" * 50)
        print("ğŸ“Š è®­ç»ƒåæµ‹è¯•...")
        
        # åŠ è½½è‡ªå®šä¹‰æ¨¡å‹è¿›è¡Œæµ‹è¯•
        if os.path.exists('custom_sentiment.marshal.3'):
            trained_model = Sentiment()
            trained_model.load('custom_sentiment.marshal.3')
            trained_acc = evaluate_model(trained_model, test_texts, test_labels)
            print(f"ã€è®­ç»ƒåã€‘æ¨¡å‹å‡†ç¡®ç‡ï¼š{trained_acc:.2%}")
            
            if 'base_acc' in locals():
                improvement = (trained_acc - base_acc) * 100
                print(f"å‡†ç¡®ç‡æå‡: {improvement:.2f}%")

    # ========== æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ==========
    try:
        if os.path.exists('temp_data'):
            shutil.rmtree('temp_data')
            print("\nğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å®Œæˆ")
    except:
        pass

    # ========== æ€»ç»“ ==========
    total_time = time.time() - start_time
    print(f"\nâ±ï¸ æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼ç”Ÿæˆçš„æ¨¡å‹æ–‡ä»¶:")
    for model_file in model_files:
        if os.path.exists(model_file):
            size = os.path.getsize(model_file)
            print(f"  ğŸ“„ {model_file} ({size:,} å­—èŠ‚)")
    
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. ç°åœ¨å¯ä»¥ä½¿ç”¨GUIå·¥å…·çš„'é€‰æ‹©æ¨¡å‹æµ‹è¯•'åŠŸèƒ½")
    print("2. é€‰æ‹©ç”Ÿæˆçš„.marshalæ–‡ä»¶è¿›è¡Œå¯¹æ¯”æµ‹è¯•")
    print("3. ä½¿ç”¨'æ¨¡å‹å¯¹æ¯”'åŠŸèƒ½æ¯”è¾ƒä¸åŒæ¨¡å‹æ•ˆæœ")
    print("\nğŸš€ å¯åŠ¨GUI: python å¯åŠ¨å·¥å…·.py")